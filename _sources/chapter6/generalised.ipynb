{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b43709-e874-4f2d-8b7e-53f69b2efe8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca4489-22b6-4171-8f1a-9d8ce3bef39a",
   "metadata": {},
   "source": [
    "## Generalised Linear Models\n",
    "`statsmodels` is far more than a linear regression powerhouse. It is also capable of fitting a range of *generalised* linear models, that allow users to fit models to non-normal data, such as binary, count, hierarchical models, and generalised estimating equations. We will explore some of these using the in-built datasets from `statsmodels`. These are located under the **non-formula** import of the package, which exposes a far wider range of functions outside of the nice formula interface we have seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dda81e4-a5e6-490f-a5b2-461b05fd17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general statsmodels\n",
    "import statsmodels.api as sm # traditional alias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe49191-0e95-430b-9410-5c19102912dd",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "We will first explore the use of logistic regression, which allows for the modelling of binary data - such as whether a trial was correct/incorrect, a participant was male/female, and so on. For this example we will use the [RAND Health Insurance Experiment data](http://www.rand.org/health/projects/hie.html) which contains a set of variables related to health insurance claims that have been used to investigate key questions in health insurance. The variables are:\n",
    "\n",
    "- `mdvis` - Number of outpatient visits to an MD\n",
    "- `lncoins` - ln(coinsurance + 1), 0 <= coninsurance <= 10\n",
    "- `idp` - 1 if individual deductible plan, 0 otherwise\n",
    "- `lpi` - ln(max(1, annual participation incentive payment)\n",
    "- `fmde` - 0 if idp = 1; ln(max(1, MDE/(0.01 coinsurance))) otherwise\n",
    "- `physlm` - 1 if the person has a physical limitation\n",
    "- `disea` - number of chronic disease\n",
    "- `hlthg` - 1 if self-rated health is good\n",
    "- `hlthf` - 1 if self-rated health is fair\n",
    "- `hlthp` - 1 if self-rated health is poor\n",
    "\n",
    "We will attempt a simple logistic regression model, predicting whether someone has an individual deductible plan, `idp` (coded as 1 if yes, and zero if no) from a few predictors - number of chronic diseases `disea`, number of outpatient visits `mdvis`, and coinsurance, the amount that has to be paid if a claim is made, `lncoins`. \n",
    "\n",
    "To fit logistic regression models, we can use the `logit` function from the formula `smf` interface, and specify our model with a formula string. But first we load the data (with a slightly unusual syntax) from the non-formula interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46796305-8c43-457f-946f-0a504d93aeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537159\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>idp</td>       <th>  No. Observations:  </th>  <td> 20190</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 20186</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 23 Jun 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.06261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:14:49</td>     <th>  Log-Likelihood:    </th> <td> -10845.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -11570.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.5700</td> <td>    0.034</td> <td>  -16.585</td> <td> 0.000</td> <td>   -0.637</td> <td>   -0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disea</th>     <td>    0.0122</td> <td>    0.003</td> <td>    4.865</td> <td> 0.000</td> <td>    0.007</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mdvis</th>     <td>   -0.0495</td> <td>    0.005</td> <td>  -10.399</td> <td> 0.000</td> <td>   -0.059</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lncoins</th>   <td>   -0.3259</td> <td>    0.009</td> <td>  -34.907</td> <td> 0.000</td> <td>   -0.344</td> <td>   -0.308</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    idp   No. Observations:                20190\n",
       "Model:                          Logit   Df Residuals:                    20186\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 23 Jun 2022   Pseudo R-squ.:                 0.06261\n",
       "Time:                        09:14:49   Log-Likelihood:                -10845.\n",
       "converged:                       True   LL-Null:                       -11570.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.5700      0.034    -16.585      0.000      -0.637      -0.503\n",
       "disea          0.0122      0.003      4.865      0.000       0.007       0.017\n",
       "mdvis         -0.0495      0.005    -10.399      0.000      -0.059      -0.040\n",
       "lncoins       -0.3259      0.009    -34.907      0.000      -0.344      -0.308\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load RAND data\n",
    "rand = sm.datasets.randhie.load_pandas().data\n",
    "\n",
    "# Fit the model\n",
    "logistic_results = smf.logit('idp ~ disea + mdvis + lncoins', data=rand).fit()\n",
    "\n",
    "# Examine the results\n",
    "logistic_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a17cd-c7e3-407d-a48b-2744b445fa4d",
   "metadata": {},
   "source": [
    "Success! But what does all this mean? Logistic regression isn't as easy to interpret as ordinary least squares, where a single unit increase in the predictor is associated with a coefficient-value change in the outcome. Logistic regression actually models the *probability* of a positive/yes/one response in the outcome variable, but does so using the **logistic function**, which maps probability space, which is zero to one, to an infinite continuous space of positive and negative. \n",
    "\n",
    "The way it does this is by converting probabilities to odds, and then taking the logarithm of the odds - the log-odds. All coefficients in logistic regression represent the change in the log-odds of the outcome with a one-unit increase of the predictor. \n",
    "\n",
    "Let's try to clear this up by looking at the model. The `mdvis` predictor shows a significant, negative relationship with the outcome on the log-odds scale. We have no idea what this means outside of that when the number of visits go up, the probability of having a deductible plan goes down. But if we *exponentiate* the coefficient, we undo the logarithm and get the odds back, which are somewhat more interpretable. `numpy` can help us here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400c4cae-c101-4758-8215-90f8dccf868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.565516\n",
       "disea        1.012295\n",
       "mdvis        0.951673\n",
       "lncoins      0.721882\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use numpy to exponentiate the coefficients\n",
    "# numpy has an .exp function\n",
    "# the coefficients are stored in the .params model attribute\n",
    "odds = np.exp(logistic_results.params)\n",
    "odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1d233-0133-4146-947d-05a7c46e616d",
   "metadata": {},
   "source": [
    "This is somewhat more interpretable. As the number of medical visits increases by one, the odds of having an individual deductible plan change by 0.95% (or indeed decrease by 5%). \n",
    "\n",
    "Unlike ordinary least squares, understanding a logistic regression model involves working closely with the predictions. We saw how to get those from an `ols` object above, but logistic regression is a different beast. While it does have a `.fittedvalues` attribute, it represents the predictions on the log-odds scale. To get at our predictions, we can do two things:\n",
    "\n",
    "- Apply the reverse transformation using `scipy.special.expit` on the `.fittedvalues` attribute. This is the inverse-log-odds transform (sometimes known as the inverse logit) and will return the probabilities of a positive response.\n",
    "- Use the `.predict` method of the fitted model to give the probabilites already back-transformed.\n",
    "\n",
    "The latter doesn't invovle an extra import but we will show both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8686cf-dd13-4a4e-b950-5adf61ea0f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import scipy function\n",
    "from scipy.special import expit\n",
    "expit_results = expit(logistic_results.fittedvalues)\n",
    "\n",
    "# Use prediction\n",
    "logistic_predictions = logistic_results.predict() # a no-argument call predicts the data the model was fitted on\n",
    "\n",
    "# Are these the same?\n",
    "np.all(expit_results == logistic_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7f50a-5ad2-4e71-90b5-d675b503ffec",
   "metadata": {},
   "source": [
    "These are equivalent operations. Let's work with the `logistic_predictions` data, and add it directly to the `rand` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c112e695-5a1b-4007-bf43-0709f930b177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdvis</th>\n",
       "      <th>lncoins</th>\n",
       "      <th>idp</th>\n",
       "      <th>lpi</th>\n",
       "      <th>fmde</th>\n",
       "      <th>physlm</th>\n",
       "      <th>disea</th>\n",
       "      <th>hlthg</th>\n",
       "      <th>hlthf</th>\n",
       "      <th>hlthp</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mdvis  lncoins  idp       lpi  fmde  physlm     disea  hlthg  hlthf  hlthp  \\\n",
       "0      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "1      2  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "2      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "3      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "4      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "\n",
       "   predictions  \n",
       "0     0.129403  \n",
       "1     0.118646  \n",
       "2     0.129403  \n",
       "3     0.129403  \n",
       "4     0.129403  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add a column\n",
    "rand['predictions'] = logistic_results.predict()\n",
    "\n",
    "display(rand.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c85b6-f87c-4dc7-bcff-1f415fb0ec35",
   "metadata": {},
   "source": [
    "Our model has given us the predictions of whether someone has an individual deductible plan. If you're not used to logistic regression it may be a surprise that you get probabilities back and not zeros and ones, which is what you have in the observed data. Its actually entirely up to *you* how you interpret those probabilities and to map them onto the observed data, but its tradition that we assume the outcome variable is a $Bernoulli$ distributed variable (stats speak for its a coin toss with 50/50 heads-tails outcomes). So, we can actually convert the probabilities into zeros and ones with a simple boolean operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c3d4a5-03c9-4990-a6b2-417e5a511a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdvis</th>\n",
       "      <th>lncoins</th>\n",
       "      <th>idp</th>\n",
       "      <th>lpi</th>\n",
       "      <th>fmde</th>\n",
       "      <th>physlm</th>\n",
       "      <th>disea</th>\n",
       "      <th>hlthg</th>\n",
       "      <th>hlthf</th>\n",
       "      <th>hlthp</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predicted_idp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mdvis  lncoins  idp       lpi  fmde  physlm     disea  hlthg  hlthf  hlthp  \\\n",
       "0      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "1      2  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "2      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "3      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "4      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "\n",
       "   predictions  predicted_idp  \n",
       "0     0.129403              0  \n",
       "1     0.118646              0  \n",
       "2     0.129403              0  \n",
       "3     0.129403              0  \n",
       "4     0.129403              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add zeros/ones\n",
    "rand['predicted_idp'] = np.where(rand['predictions'] <= .50, 0, 1)\n",
    "\n",
    "rand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b34527-9fdb-423e-a692-4a416f3621d2",
   "metadata": {},
   "source": [
    "We can now examine how well the model did in terms of its predictions, by computing the terrifyingly named *confusion matrix*. All this represents is how our model did - for example, when a datapoint *did* have an individual deductible, how many times did the model say it did? What about the reverse - did it say no when it should have said no? \n",
    "\n",
    "Evaluating the performance of logistic regression models is an entire sub-field of statistics in and of itself. You will sometime see terms like precision, recall, accuracy, true positive rate, false positive rate, and many, many more floating around. All of these refer to - basically - is whether the model is saying 'yes' when it should and 'no' when it should, and there are many variations along that theme. Personally I find this the most confusing part of statistical practice and find myself always referring to [this diagram](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram) when working here - I am sure you will too!\n",
    "\n",
    "Let's use the `pd.crosstab` function to build the confusion matrix, which takes two columns of 1/0 responses and counts the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13bcf1e8-0b2c-451b-b5ae-f1a70f34b151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted_idp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14939</td>\n",
       "      <td>2</td>\n",
       "      <td>14941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5249</td>\n",
       "      <td>0</td>\n",
       "      <td>5249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>20188</td>\n",
       "      <td>2</td>\n",
       "      <td>20190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted_idp      0  1    All\n",
       "idp                           \n",
       "0              14939  2  14941\n",
       "1               5249  0   5249\n",
       "All            20188  2  20190"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted_idp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739921</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.74002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted_idp         0         1      All\n",
       "idp                                       \n",
       "0              0.739921  0.000099  0.74002\n",
       "1              0.259980  0.000000  0.25998\n",
       "All            0.999901  0.000099  1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crosstabs can be normalised or not, depending on the use of the `normalize` keyword\n",
    "confused1 = pd.crosstab(rand['idp'], rand['predicted_idp'], margins=True, normalize=False)\n",
    "confused2 = pd.crosstab(rand['idp'], rand['predicted_idp'], margins=True, normalize=True)\n",
    "display(confused1, confused2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4feeb88-8ab2-4bf7-9f9d-3b485511ad03",
   "metadata": {},
   "source": [
    "What this hopefully highlights is that, despite obtaining significant coefficients, the predictions of the model here were pretty poor - in fact, our model barely made a positive prediction! Only 2 cases (both wrong, ironically) were predicted as positive. This would be a good time to revise the model and include extra predictors. \n",
    "\n",
    "Classification is a surprisingly difficult area of statistics - be sure to look beyond model fit and p-values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736c93f-191e-43c0-ab0a-a643100ce65d",
   "metadata": {},
   "source": [
    "### Poisson or Negative Binomial models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20843f9a-ce2b-44a0-bf4a-e297ffac9289",
   "metadata": {},
   "source": [
    "Though not encountered too often in psychological science, data that are distributed as counts are popular across other fields and are becoming more popular in research. Count data represent data that are coded as whole numbers (integers) that start at zero and have no upper limit. Normal regression models like ordinary least squares may make negative count predictions, or fractional predictions, which make little sense (what does it mean to have, say, negative counts of a behaviour, or 2.31201 instance of a behaviour?).\n",
    "\n",
    "Fortunately, count data can be modelled relatively simply with either a $Poisson$ or $Negative Binomial$ regression. These models are named after the distributions of the same name which describe the probability of count data. The Poisson is a straightforward single-parameter distribution that describes distributions of counts. The single parameter is sometimes called the 'rate', and it represents the average of all the count data in a Poisson distribution. So while the Poisson distribution produces whole-integer values, its parameter can be a continuous (positive!) value. \n",
    "\n",
    "The negative binomial is traditionally used to describe the probability of observing a number of failures before a single success - e.g. how many times must I roll a dice *before* I get a 3? The number of 'fails' (roll != 3) would be modelled by the negative binomial. \n",
    "\n",
    "Sometimes, the single-parameter Poisson does a good enough job in regression contexts. However sometimes we encounter a phenomenon called *over-dispersion*, which is where the variability of the counts exceeds the average tendency. Fortunately, the negative binomial can be used instead, as it allows for a second parameter to incorporate the variability. \n",
    "\n",
    "If this sounds too technical, don't worry - it really is. The details are not vital; what we need to focus on is if we are dealing with count data, we can start with the Poisson model, check for this overdispersion, and if it appears, switch to the negative binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795b5d1-67a2-4d7c-8308-e9d0b0dbe727",
   "metadata": {},
   "source": [
    "#### Poisson Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b65de-7831-4763-8f47-f3b4beb319e8",
   "metadata": {},
   "source": [
    "Using the `rand` data, we could think of a different research question, asking whether the number of medical visits `mdvis` (a count variable!) is influenced by the coinsurance payment `lncoins`, as well as the number of chronic diseases, `disea`. Doing this in `statsmodels` is very easy - same idea as before; get the formula ready and use the `Poisson` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc65c7c-ef19-4493-8fca-f0d9bfb47c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 3.141408\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Poisson Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>mdvis</td>      <th>  No. Observations:  </th>  <td> 20190</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>Poisson</td>     <th>  Df Residuals:      </th>  <td> 20187</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 23 Jun 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.04835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:14:49</td>     <th>  Log-Likelihood:    </th> <td> -63425.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -66647.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.6474</td> <td>    0.009</td> <td>   75.120</td> <td> 0.000</td> <td>    0.630</td> <td>    0.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lncoins</th>   <td>   -0.0597</td> <td>    0.002</td> <td>  -27.788</td> <td> 0.000</td> <td>   -0.064</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disea</th>     <td>    0.0409</td> <td>    0.001</td> <td>   81.383</td> <td> 0.000</td> <td>    0.040</td> <td>    0.042</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Poisson Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  mdvis   No. Observations:                20190\n",
       "Model:                        Poisson   Df Residuals:                    20187\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 23 Jun 2022   Pseudo R-squ.:                 0.04835\n",
       "Time:                        09:14:49   Log-Likelihood:                -63425.\n",
       "converged:                       True   LL-Null:                       -66647.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.6474      0.009     75.120      0.000       0.630       0.664\n",
       "lncoins       -0.0597      0.002    -27.788      0.000      -0.064      -0.055\n",
       "disea          0.0409      0.001     81.383      0.000       0.040       0.042\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Poisson regression\n",
    "poisson_results = smf.poisson('mdvis ~ lncoins + disea', data=rand).fit()\n",
    "\n",
    "# Summarise\n",
    "poisson_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264683c0-e8f0-435a-9254-6117d827895c",
   "metadata": {},
   "source": [
    "Great, some results! What do these mean again? \n",
    "\n",
    "Like logistic regression, Poisson regression uses a special kind of function to transform the outcome variable in order to model it. It uses a log-transform, which means the coefficients are on the log-scale. That is, as the predictor increases, the log-count of the variable increases by one. As before we can exponentiate these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af147c0-b397-4084-821b-1f9c2d405974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    1.910517\n",
       "lncoins      0.942055\n",
       "disea        1.041777\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exponentiate\n",
    "display(np.exp(poisson_results.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97af27-a1eb-4df0-9be9-e4b570d163be",
   "metadata": {},
   "source": [
    "That is somewhat clearer - as the number of diseases increases, so does the count of doctors visits. And, as the premium goes up, the number of visits go down. This makes sense, the pricier it is to get healthcare, the less likely you are to go. \n",
    "\n",
    "As with other kinds of generalized linear models, its often easier to work with the predictions directly to draw some conclusions. If we call the `.predict` method on fitted Poisson regression model, we will get the predictions back with no transformations needed. If you want to verify its correct you can exponentiate the `.fittedvalues` attribute and you will get the same results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f8b174-0d5e-494d-a980-01e9b3e1a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdvis</th>\n",
       "      <th>lncoins</th>\n",
       "      <th>idp</th>\n",
       "      <th>lpi</th>\n",
       "      <th>fmde</th>\n",
       "      <th>physlm</th>\n",
       "      <th>disea</th>\n",
       "      <th>hlthg</th>\n",
       "      <th>hlthf</th>\n",
       "      <th>hlthp</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predicted_idp</th>\n",
       "      <th>predicted_mdvis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mdvis  lncoins  idp       lpi  fmde  physlm     disea  hlthg  hlthf  hlthp  \\\n",
       "0      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "1      2  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "2      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "3      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "4      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "\n",
       "   predictions  predicted_idp  predicted_mdvis  \n",
       "0     0.129403              0         2.544425  \n",
       "1     0.118646              0         2.544425  \n",
       "2     0.129403              0         2.544425  \n",
       "3     0.129403              0         2.544425  \n",
       "4     0.129403              0         2.544425  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call predict and store the predictions in the rand dataframe\n",
    "rand['predicted_mdvis'] = poisson_results.predict()\n",
    "\n",
    "display(rand.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f303d29-69ef-4538-95e9-179b4358d4ec",
   "metadata": {},
   "source": [
    "Something unusual is going on. The predicted values are floating numbers, *not* count data. Whats happening here? Much like with ordinary least squares and logistic regression, Poisson regression is predicting the *expected* value of the observed data point - essentially, what the average value of that data point would be, given its values on the predictors. So what we are really looking at here is the parameter or 'rate' of the distribution that the data point came from!\n",
    "\n",
    "We can expand our fishing adventures by using an alternative function in the results object of a Poisson regression, `.predict_prob`. This function takes the predicted rate (our `predicted_mdvis` variable above, and it does something quite clever:\n",
    "\n",
    "- It takes all the whole numbers from zero the maximum count value observed in the data.\n",
    "- For each datapoint, it takes the predicted rate, and builds a *probability mass function* from a Poisson distribution with *that* rate. What's a probability mass function?! Its just the probability of seeing a specific count value, given a particular Poisson 'rate'. \n",
    "- It returns all of those probabilities to us, and we can see what has the highest value - the most probable count value of our data.\n",
    "\n",
    "This is going to be a little tricky to unpack, so lets do this step by step in the order above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55589953-9fea-4118-8908-71f38aa531b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078518</td>\n",
       "      <td>0.199784</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.21557</td>\n",
       "      <td>0.137125</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>...</td>\n",
       "      <td>1.203950e-70</td>\n",
       "      <td>4.439651e-72</td>\n",
       "      <td>1.613766e-73</td>\n",
       "      <td>5.783247e-75</td>\n",
       "      <td>2.043755e-76</td>\n",
       "      <td>7.123537e-78</td>\n",
       "      <td>2.449365e-79</td>\n",
       "      <td>8.309635e-81</td>\n",
       "      <td>2.782006e-82</td>\n",
       "      <td>9.192993e-84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078518</td>\n",
       "      <td>0.199784</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.21557</td>\n",
       "      <td>0.137125</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>...</td>\n",
       "      <td>1.203950e-70</td>\n",
       "      <td>4.439651e-72</td>\n",
       "      <td>1.613766e-73</td>\n",
       "      <td>5.783247e-75</td>\n",
       "      <td>2.043755e-76</td>\n",
       "      <td>7.123537e-78</td>\n",
       "      <td>2.449365e-79</td>\n",
       "      <td>8.309635e-81</td>\n",
       "      <td>2.782006e-82</td>\n",
       "      <td>9.192993e-84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2        3         4         5         6   \\\n",
       "0  0.078518  0.199784  0.254167  0.21557  0.137125  0.069781  0.029592   \n",
       "1  0.078518  0.199784  0.254167  0.21557  0.137125  0.069781  0.029592   \n",
       "\n",
       "         7         8         9   ...            68            69  \\\n",
       "0  0.010756  0.003421  0.000967  ...  1.203950e-70  4.439651e-72   \n",
       "1  0.010756  0.003421  0.000967  ...  1.203950e-70  4.439651e-72   \n",
       "\n",
       "             70            71            72            73            74  \\\n",
       "0  1.613766e-73  5.783247e-75  2.043755e-76  7.123537e-78  2.449365e-79   \n",
       "1  1.613766e-73  5.783247e-75  2.043755e-76  7.123537e-78  2.449365e-79   \n",
       "\n",
       "             75            76            77  \n",
       "0  8.309635e-81  2.782006e-82  9.192993e-84  \n",
       "1  8.309635e-81  2.782006e-82  9.192993e-84  \n",
       "\n",
       "[2 rows x 78 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a set of values from zero to the maximum observed in our data\n",
    "# We add one because of Pythons 'up to but don't include' rule - see chapter 1!\n",
    "counts = np.arange(0, max(rand['mdvis'] + 1))\n",
    "\n",
    "# Get the probability mass of each datapoint, given the predicted rate!\n",
    "probability_mass = poisson_results.predict_prob()\n",
    "\n",
    "# Put these in a dataframe\n",
    "prob_mass_df = pd.DataFrame(probability_mass, columns=counts)\n",
    "display(prob_mass_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c1c2d-94b6-489c-a9cb-9044d961984b",
   "metadata": {},
   "source": [
    "OK! Only two datapoints are shown but we have the probability that the datapoint is the count shown in the DataFrame header, given the predicted rate. If we want to collapse this into a single number, all we need to is take index with the maximum value (i.e. , for row one, what is the column with the highest probability?)\n",
    "\n",
    "`pandas` can help here, with the `.idxmax` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "088b458c-0689-4f65-93cd-a96bad864547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdvis</th>\n",
       "      <th>lncoins</th>\n",
       "      <th>idp</th>\n",
       "      <th>lpi</th>\n",
       "      <th>fmde</th>\n",
       "      <th>physlm</th>\n",
       "      <th>disea</th>\n",
       "      <th>hlthg</th>\n",
       "      <th>hlthf</th>\n",
       "      <th>hlthp</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predicted_idp</th>\n",
       "      <th>predicted_mdvis</th>\n",
       "      <th>predicted_count_mdvis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.61512</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.73189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129403</td>\n",
       "      <td>0</td>\n",
       "      <td>2.544425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mdvis  lncoins  idp       lpi  fmde  physlm     disea  hlthg  hlthf  hlthp  \\\n",
       "0      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "1      2  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "2      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "3      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "4      0  4.61512    1  6.907755   0.0     0.0  13.73189      1      0      0   \n",
       "\n",
       "   predictions  predicted_idp  predicted_mdvis  predicted_count_mdvis  \n",
       "0     0.129403              0         2.544425                      2  \n",
       "1     0.118646              0         2.544425                      2  \n",
       "2     0.129403              0         2.544425                      2  \n",
       "3     0.129403              0         2.544425                      2  \n",
       "4     0.129403              0         2.544425                      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign this back to the rand data\n",
    "rand['predicted_count_mdvis'] = prob_mass_df.idxmax(axis='columns')\n",
    "\n",
    "display(rand.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f12c5-8d9b-4689-a5cc-93ece3ec6770",
   "metadata": {},
   "source": [
    "OK, now we have predicted counts! What does that look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86221ec8-3ad9-45e5-940b-03b528b8444a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='predicted_count_mdvis', ylabel='mdvis'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(y=rand['mdvis'], x=rand['predicted_count_mdvis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb93b98-519b-4df7-b5c1-4323e0c8d3f0",
   "metadata": {},
   "source": [
    "Not great, sadly. The model is really under-predicting - the observed data goes from 0 to 77, but the predictions only top 20. Is our data over-dispersed? We can check this, but it involves a little manual calculation - nothing too bad, though. First we take the models *Pearson residuals*, square them, and sum them. Then we divide this by the residual degrees of freedom of the model. If the result is greater than 1, we have evidence of overdispersion and should switch our modelling strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a3e336-dee2-42a0-af84-56531f24f961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.437470502281646 True\n"
     ]
    }
   ],
   "source": [
    "# Compute overdispersion\n",
    "od = (poisson_results.resid_pearson ** 2 ).sum() / poisson_results.df_resid\n",
    "\n",
    "print(od, od > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e265bb6d-27a9-4b44-87c3-78a2fe273e82",
   "metadata": {},
   "source": [
    "That might explain our not-so-good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2a4f9-401a-4354-b70a-d1ab3ec20a8a",
   "metadata": {},
   "source": [
    "#### Negative Binomial Regression\n",
    "Fitting a negative binomial regression at this point should be intuitive - we simply set up the formula, and pass it directly to the `negativebinomial` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f884c502-99a0-4627-9240-2a5659f9dda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.159078\n",
      "         Iterations: 13\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>NegativeBinomial Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>mdvis</td>      <th>  No. Observations:  </th>   <td> 20190</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>           <td>NegativeBinomial</td> <th>  Df Residuals:      </th>   <td> 20187</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 23 Jun 2022</td> <th>  Pseudo R-squ.:     </th>   <td>0.01374</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:14:50</td>     <th>  Log-Likelihood:    </th>  <td> -43592.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -44199.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.480e-264</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.6264</td> <td>    0.020</td> <td>   31.766</td> <td> 0.000</td> <td>    0.588</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lncoins</th>   <td>   -0.0633</td> <td>    0.005</td> <td>  -13.482</td> <td> 0.000</td> <td>   -0.072</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disea</th>     <td>    0.0431</td> <td>    0.001</td> <td>   31.612</td> <td> 0.000</td> <td>    0.040</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alpha</th>     <td>    1.3365</td> <td>    0.019</td> <td>   70.288</td> <td> 0.000</td> <td>    1.299</td> <td>    1.374</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                     NegativeBinomial Regression Results                      \n",
       "==============================================================================\n",
       "Dep. Variable:                  mdvis   No. Observations:                20190\n",
       "Model:               NegativeBinomial   Df Residuals:                    20187\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 23 Jun 2022   Pseudo R-squ.:                 0.01374\n",
       "Time:                        09:14:50   Log-Likelihood:                -43592.\n",
       "converged:                       True   LL-Null:                       -44199.\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.480e-264\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.6264      0.020     31.766      0.000       0.588       0.665\n",
       "lncoins       -0.0633      0.005    -13.482      0.000      -0.072      -0.054\n",
       "disea          0.0431      0.001     31.612      0.000       0.040       0.046\n",
       "alpha          1.3365      0.019     70.288      0.000       1.299       1.374\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model \n",
    "negbinom_results = smf.negativebinomial('mdvis ~ lncoins + disea', data=rand).fit()\n",
    "\n",
    "# Get summary\n",
    "negbinom_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ebb45-151f-4ed2-87bf-9e5f8eafa3df",
   "metadata": {},
   "source": [
    "The interpretation of the coefficients is much the same as the Poisson regression case, with the estimates representing the change in the log-counts of the outcome variable with a one-unit change in the predictor variable. Exponentiating them casts them on an odds scale. \n",
    "\n",
    "You may notice the model seems to have an extra estimate - `alpha` - that also has a significance test associated with it. This is the **overdispersion parameter**. Recall that the Poisson distribution has a single parameter, the 'rate', or average. If the counts vary a lot, the Poisson will find it difficult to model the variability with a single parameter. The negative binomial distribution has a similar rate or average, but also has an additional parameter, alpha, which controls the variability of the counts. The model tests whether this value is significantly different from zero, which seems to be the case here. It's another way of examining over-dispersion! Interestingly, if this parameter equals zero, the model is mathematically equivalent to a Poisson regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
