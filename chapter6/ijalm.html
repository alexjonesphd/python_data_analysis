
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>5. Bonus section - Its Just A Linear Model &#8212; An introduction to data analysis in Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="4. Hierarchical or mixed models" href="lmm.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">An introduction to data analysis in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    An introduction to data analysis in Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter1/the_basics.html">
   1. The Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter1/data_collections.html">
   2. Data collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter1/functions.html">
   3. Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter1/loops.html">
   4. Loops
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NumPy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter2/imports.html">
   1. Starting data handling in Python - NumPy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter2/basic_numpy.html">
   2. The
   <code class="docutils literal notranslate">
    <span class="pre">
     numpy
    </span>
   </code>
   module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter2/stats_simulation.html">
   3. Data indexing, simulation, and summary statistics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  pandas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter3/pandas_import_describe.html">
   1. The
   <code class="docutils literal notranslate">
    <span class="pre">
     pandas
    </span>
   </code>
   module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter3/indexing.html">
   2. Accessing data in Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter3/booleans.html">
   3. Boolean operations with Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter3/split_apply_combine.html">
   4. The power of
   <code class="docutils literal notranslate">
    <span class="pre">
     groupby
    </span>
   </code>
   and aggregation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter3/custom_functions_flow.html">
   5. Custom functions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  pandas - advanced uses
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter4/apply.html">
   1. Advanced data handling with
   <code class="docutils literal notranslate">
    <span class="pre">
     pandas
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter4/go_long.html">
   2. Data surgery - reshaping data with
   <code class="docutils literal notranslate">
    <span class="pre">
     melt
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter4/go_wide.html">
   3. There and back again - reshaping data with
   <code class="docutils literal notranslate">
    <span class="pre">
     .pivot_table()
    </span>
   </code>
   .
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter4/merge_join.html">
   4. Data surgery - joining DataFrames with
   <code class="docutils literal notranslate">
    <span class="pre">
     pd.concat
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     pd.merge
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Visualisation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter5/matplotlib.html">
   1. Introducing
   <code class="docutils literal notranslate">
    <span class="pre">
     matplotlib
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter5/seaborn.html">
   2. Using
   <code class="docutils literal notranslate">
    <span class="pre">
     seaborn
    </span>
   </code>
   for smoother data visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter5/advanced_seaborn.html">
   3. Advanced plotting with
   <code class="docutils literal notranslate">
    <span class="pre">
     seaborn
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistical Analysis
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="pingouin.html">
   1. (Frequentist) Statistics in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="statsmodels.html">
   2. Statistics with
   <code class="docutils literal notranslate">
    <span class="pre">
     statsmodels
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     scipy.stats
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="generalised.html">
   3. Generalised Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lmm.html">
   4. Hierarchical or mixed models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5.
   <strong>
    Bonus section
   </strong>
   -
   <strong>
    I
   </strong>
   ts
   <strong>
    J
   </strong>
   ust
   <strong>
    A
   </strong>
   <strong>
    L
   </strong>
   inear
   <strong>
    M
   </strong>
   odel
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/chapter6/ijalm.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fchapter6/ijalm.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/chapter6/ijalm.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   5.
   <strong>
    Bonus section
   </strong>
   -
   <strong>
    I
   </strong>
   ts
   <strong>
    J
   </strong>
   ust
   <strong>
    A
   </strong>
   <strong>
    L
   </strong>
   inear
   <strong>
    M
   </strong>
   odel
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-t-test-is-regression">
     5.1. A t-test is regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-paired-t-test-as-regression">
     5.2. A paired t-test as regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-one-way-anova-is-regression">
     5.3. A one-way ANOVA is regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factorial-anova-s-are-also-regressions">
     5.4. Factorial ANOVA’s are also regressions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-deep-dive-into-statistics-factorial-anova-designs-as-linear-models">
     5.5. A deep dive into statistics - factorial ANOVA designs as linear models
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#measuring-error-and-r-2">
     5.6. Measuring error and
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-much-better-a-model-comparison-via-differences-in-error">
   6. How much better? A model comparison via differences in error
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-anova-does">
     6.1. What ANOVA does
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bonus section - Its Just A Linear Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   5.
   <strong>
    Bonus section
   </strong>
   -
   <strong>
    I
   </strong>
   ts
   <strong>
    J
   </strong>
   ust
   <strong>
    A
   </strong>
   <strong>
    L
   </strong>
   inear
   <strong>
    M
   </strong>
   odel
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-t-test-is-regression">
     5.1. A t-test is regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-paired-t-test-as-regression">
     5.2. A paired t-test as regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-one-way-anova-is-regression">
     5.3. A one-way ANOVA is regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factorial-anova-s-are-also-regressions">
     5.4. Factorial ANOVA’s are also regressions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-deep-dive-into-statistics-factorial-anova-designs-as-linear-models">
     5.5. A deep dive into statistics - factorial ANOVA designs as linear models
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#measuring-error-and-r-2">
     5.6. Measuring error and
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-much-better-a-model-comparison-via-differences-in-error">
   6. How much better? A model comparison via differences in error
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-anova-does">
     6.1. What ANOVA does
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pingouin</span> <span class="k">as</span> <span class="nn">pg</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
</pre></div>
</div>
</div>
</div>
<section id="bonus-section-its-just-a-linear-model">
<h1><span class="section-number">5. </span><strong>Bonus section</strong> - <strong>I</strong>ts <strong>J</strong>ust <strong>A</strong> <strong>L</strong>inear <strong>M</strong>odel<a class="headerlink" href="#bonus-section-its-just-a-linear-model" title="Permalink to this headline">#</a></h1>
<p>The teaching of statistics, especially in psychology, is presented as a dazzling array of tools - a Swiss army knife of options that is typically overwhelming for new (and old) students. The typical practice involves a rote, algorithmic approach to statistical inference, whereby the confusion is somewhat reduced by selecting the appropriate test from the huge range on offer. The typical conversation goes like this:</p>
<ul class="simple">
<li><p>Do you want to compare two or more means? Four please!</p></li>
<li><p>Do any of observations provide data in the different variables that make up the means? Yes they do!</p></li>
<li><p>Actually, do <em>all</em> of the observatiins provide data in the different variables? No, only some.</p></li>
<li><p>Then you need a mixed-factorial ANOVA. Wait, is that the same as a mixed model?</p></li>
<li><p>No. That’s a form of regression.</p></li>
<li><p>So regression can’t be used with groups?</p></li>
<li><p>It can.</p></li>
<li><p>Oh no.</p></li>
</ul>
<p>The problem with the algorithmic approach is, while it eases confusion initially (though I would argue that’s not really the case) it masks the elegance of statistical inference from learners. In fact, the vast majority of classic statistical inference approaches used across quantitative science are forms of the steadfast ordinary least squares model. Really - everythig is a regression. To use the words of Professor Daniela Witten, its just a linear model (IJALM)!</p>
<p>Below I will walk through some examples of common statistical tests in psychology and express them as linear regressions using the <code class="docutils literal notranslate"><span class="pre">ols</span></code> function from <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>, also showing how the formula interface can be used to modify data in a model.</p>
<section id="a-t-test-is-regression">
<h2><span class="section-number">5.1. </span>A t-test is regression<a class="headerlink" href="#a-t-test-is-regression" title="Permalink to this headline">#</a></h2>
<p>The difference between two groups is equivalent to a simple regression, with a single predictor - a predictor which codes which group the observation belongs to. What numbers you use don’t matter, as long as they are different. Fortunately, <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> takes care of that for us if we use a formula - it is smart enough to recode the data!</p>
<p>First lets look at a between-groups t-test using <code class="docutils literal notranslate"><span class="pre">pingouin</span></code> on the <code class="docutils literal notranslate"><span class="pre">tips</span></code> dataset, testing for differences in the amount of tips given by male and female patrons.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load tips</span>
<span class="n">tips</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;tips&#39;</span><span class="p">)</span>

<span class="c1"># Display result of t-test using pingouin, with no correction on unbalanced groups</span>
<span class="n">pg</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">tips</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="s1">&#39;tip&#39;</span><span class="p">],</span> 
         <span class="n">tips</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="s1">&#39;tip&#39;</span><span class="p">],</span> <span class="n">correction</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T</th>
      <th>dof</th>
      <th>alternative</th>
      <th>p-val</th>
      <th>CI95%</th>
      <th>cohen-d</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>T-test</th>
      <td>-1.38786</td>
      <td>242</td>
      <td>two-sided</td>
      <td>0.166456</td>
      <td>[-0.62, 0.11]</td>
      <td>0.185494</td>
      <td>0.361</td>
      <td>0.282179</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now fit a linear model, predicting tip by sex</span>
<span class="n">ttest_linear_mod</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;tip ~ sex&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">tips</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Show</span>
<span class="n">ttest_linear_mod</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.008</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.926</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 09 Jul 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.166</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>11:56:23</td>     <th>  Log-Likelihood:    </th> <td> -423.98</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   852.0</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   242</td>      <th>  BIC:               </th> <td>   859.0</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    3.0896</td> <td>    0.110</td> <td>   28.032</td> <td> 0.000</td> <td>    2.873</td> <td>    3.307</td>
</tr>
<tr>
  <th>sex[T.Female]</th> <td>   -0.2562</td> <td>    0.185</td> <td>   -1.388</td> <td> 0.166</td> <td>   -0.620</td> <td>    0.107</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>75.995</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 194.975</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 1.415</td> <th>  Prob(JB):          </th> <td>4.59e-43</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.342</td> <th>  Cond. No.          </th> <td>    2.42</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>The coefficient of sex, contrasting male to female, has the same <em>t</em>-value as the result of a normal <em>t</em>-test. Let’s take a moment to examine the intercept value - 3.096, and the coefficient value, -0.2562. If we compute the mean tip amount in our dataset by sex, we should find something interesting:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the mean tip per sex</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">tips</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;sex&#39;</span><span class="p">)[</span><span class="s1">&#39;tip&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>

<span class="c1"># Now compute the difference between those means, using .diff of pandas, which subtracts row-wise</span>
<span class="n">display</span><span class="p">(</span><span class="n">means</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sex
Male      3.089618
Female    2.833448
Name: tip, dtype: float64
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sex
Male         NaN
Female   -0.2562
Name: tip, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The coefficient represents the difference between going from the average of the male tip to the average of female tip. The intercept in the model is equal to the male tip mean!</p>
</section>
<section id="a-paired-t-test-as-regression">
<h2><span class="section-number">5.2. </span>A paired t-test as regression<a class="headerlink" href="#a-paired-t-test-as-regression" title="Permalink to this headline">#</a></h2>
<p>A paired <em>t</em>-test asks whether the <em>difference</em> between two conditions, for the same observations providing the data, is statistically significant from zero. We demonstrate this equivlance by first carrying out a paired test, then computing the difference between conditions, and subjecting that variable to a one sample <em>t</em>-test. Let’s load the <code class="docutils literal notranslate"><span class="pre">iris</span></code> dataset, which has measures on flower dimensions for different species, and look at the differences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load iris from seaborn</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;iris&#39;</span><span class="p">)</span>

<span class="c1"># Compute paired t-test between sepal and petal length</span>
<span class="n">normal_t</span> <span class="o">=</span> <span class="n">pg</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">],</span> <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Work out the difference and submit to a one sample t-test, using the same function with &#39;zero&#39; as second input</span>
<span class="n">difference</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">]</span>
<span class="n">one_sample</span> <span class="o">=</span> <span class="n">pg</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">difference</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">normal_t</span><span class="p">,</span> <span class="n">one_sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T</th>
      <th>dof</th>
      <th>alternative</th>
      <th>p-val</th>
      <th>CI95%</th>
      <th>cohen-d</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>T-test</th>
      <td>22.81322</td>
      <td>149</td>
      <td>two-sided</td>
      <td>1.799629e-50</td>
      <td>[1.9, 2.27]</td>
      <td>1.512468</td>
      <td>1.018e+47</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T</th>
      <th>dof</th>
      <th>alternative</th>
      <th>p-val</th>
      <th>CI95%</th>
      <th>cohen-d</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>T-test</th>
      <td>22.81322</td>
      <td>149</td>
      <td>two-sided</td>
      <td>1.799629e-50</td>
      <td>[1.9, 2.27]</td>
      <td>1.862692</td>
      <td>1.018e+47</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It should be no surprise that we can analyse this with a regression too. We want to predict the difference between two conditions using the mean of those differences. This will also allow us a demonstration of how, in formulas, you can use functions to alter your variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up the paired-test formula string</span>
<span class="n">paired_formula</span> <span class="o">=</span> <span class="s1">&#39;np.subtract(sepal_length, petal_length) ~ 1&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>This formula allows us to call the <code class="docutils literal notranslate"><span class="pre">np.subtract</span></code> function, which subtracts two vectors, and predict it using the number one - this is regression speak for ‘use the mean of the variable’!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Regression</span>
<span class="n">paired_regression</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">paired_formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">iris</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">paired_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>np.subtract(sepal_length, petal_length)</td> <th>  R-squared:         </th> <td>   0.000</td>
</tr>
<tr>
  <th>Model:</th>                              <td>OLS</td>                   <th>  Adj. R-squared:    </th> <td>   0.000</td>
</tr>
<tr>
  <th>Method:</th>                        <td>Least Squares</td>              <th>  F-statistic:       </th> <td>     nan</td>
</tr>
<tr>
  <th>Date:</th>                        <td>Sat, 09 Jul 2022</td>             <th>  Prob (F-statistic):</th>  <td>   nan</td> 
</tr>
<tr>
  <th>Time:</th>                            <td>11:56:23</td>                 <th>  Log-Likelihood:    </th> <td> -229.28</td>
</tr>
<tr>
  <th>No. Observations:</th>                 <td>   150</td>                  <th>  AIC:               </th> <td>   460.6</td>
</tr>
<tr>
  <th>Df Residuals:</th>                     <td>   149</td>                  <th>  BIC:               </th> <td>   463.6</td>
</tr>
<tr>
  <th>Df Model:</th>                         <td>     0</td>                  <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>                 <td>nonrobust</td>                <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    2.0853</td> <td>    0.091</td> <td>   22.813</td> <td> 0.000</td> <td>    1.905</td> <td>    2.266</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>68.329</td> <th>  Durbin-Watson:     </th> <td>   0.175</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  14.580</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.469</td> <th>  Prob(JB):          </th> <td>0.000682</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 1.795</td> <th>  Cond. No.          </th> <td>    1.00</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>The same! What is the mean difference?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">difference</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0853333333333333
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-one-way-anova-is-regression">
<h2><span class="section-number">5.3. </span>A one-way ANOVA is regression<a class="headerlink" href="#a-one-way-anova-is-regression" title="Permalink to this headline">#</a></h2>
<p>You may have heard that an ANOVA is a regression. This is true - IJALM - the predictors are simply variables that code which group the data belongs to. Let’s examine the <code class="docutils literal notranslate"><span class="pre">exercise</span></code> dataset, which has several between-subjects variables. We will focus on the exercise <code class="docutils literal notranslate"><span class="pre">kind</span></code> variable - there are three groups of participants and each do a different exercise, where their pulse is measured.</p>
<p>First, we will analyse it using a simple one way ANOVA, and do follow up tests.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load exercise</span>
<span class="n">exercise</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;exercise&#39;</span><span class="p">)</span>

<span class="c1"># Anova for exercise data, where DV is pulse the the between subjects factor is exercise kind</span>
<span class="n">anova</span> <span class="o">=</span> <span class="n">pg</span><span class="o">.</span><span class="n">anova</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">exercise</span><span class="p">,</span> <span class="n">dv</span><span class="o">=</span><span class="s1">&#39;pulse&#39;</span><span class="p">,</span> <span class="n">between</span><span class="o">=</span><span class="s1">&#39;kind&#39;</span><span class="p">)</span>

<span class="c1"># We will also compute the means to display</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">exercise</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;kind&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;pulse&#39;</span><span class="p">:</span> <span class="s1">&#39;mean&#39;</span><span class="p">})</span>

<span class="c1"># Show</span>
<span class="n">display</span><span class="p">(</span><span class="n">anova</span><span class="p">,</span> <span class="n">means</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Source</th>
      <th>ddof1</th>
      <th>ddof2</th>
      <th>F</th>
      <th>p-unc</th>
      <th>np2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>kind</td>
      <td>2</td>
      <td>87</td>
      <td>31.987038</td>
      <td>3.862193e-11</td>
      <td>0.423742</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pulse</th>
    </tr>
    <tr>
      <th>kind</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>rest</th>
      <td>90.833333</td>
    </tr>
    <tr>
      <th>walking</th>
      <td>95.200000</td>
    </tr>
    <tr>
      <th>running</th>
      <td>113.066667</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now, lets fit this as a ordinary least squares regression, to illustrate these tests are one and the same. All we need is to specify what we want to predict - pulse - and from what - exercise kind - and the model will take care of everything for us.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the model</span>
<span class="n">reg_anova</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ kind&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Display the summary</span>
<span class="n">reg_anova</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>pulse</td>      <th>  R-squared:         </th> <td>   0.424</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.410</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.99</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 09 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>3.86e-11</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:56:24</td>     <th>  Log-Likelihood:    </th> <td> -345.27</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   696.5</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    87</td>      <th>  BIC:               </th> <td>   704.0</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>       <td>   90.8333</td> <td>    2.083</td> <td>   43.610</td> <td> 0.000</td> <td>   86.693</td> <td>   94.973</td>
</tr>
<tr>
  <th>kind[T.walking]</th> <td>    4.3667</td> <td>    2.946</td> <td>    1.482</td> <td> 0.142</td> <td>   -1.488</td> <td>   10.221</td>
</tr>
<tr>
  <th>kind[T.running]</th> <td>   22.2333</td> <td>    2.946</td> <td>    7.548</td> <td> 0.000</td> <td>   16.379</td> <td>   28.088</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 9.099</td> <th>  Durbin-Watson:     </th> <td>   1.753</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.011</td> <th>  Jarque-Bera (JB):  </th> <td>   9.342</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.612</td> <th>  Prob(JB):          </th> <td> 0.00936</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.996</td> <th>  Cond. No.          </th> <td>    3.73</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>There are notable differences between the <code class="docutils literal notranslate"><span class="pre">pingouin</span></code> output and the OLS solution. First, the F statistic and effect size (<span class="math notranslate nohighlight">\(R^2\)</span> for regression, partial <span class="math notranslate nohighlight">\(\eta^2\)</span> for ANOVA) are identical. Its the same thing - IJALM explaining variance. But what to make of the coefficients? We have an intercept, and a ‘walking’ and ‘running’ coefficient. These coefficients represent the <em>mean difference</em> between, say, the walking condition, and the baseline (which here is implicitly <em>rest</em>). So if we add the intercept and the walking estimates together, we will get the mean of the walking condition. Try it! Notice that the intercept value is identical to the mean of the rest variable above. All the coefficients represent is moving from ‘rest’ to the other conditions. The significance tests help you interpret whether those differences are meaningful.</p>
<p>We can control what level goes into the intercept, too. We re-fit the model below and specify that ‘walking’ should be the baseline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the model, but specify the baseline to be &#39;walking&#39; by specifying a contrast like so</span>
<span class="n">reg_anova</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ C(kind, Treatment(reference=&quot;walking&quot;))&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Display the summary</span>
<span class="n">reg_anova</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>pulse</td>      <th>  R-squared:         </th> <td>   0.424</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.410</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.99</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 09 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>3.86e-11</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:56:24</td>     <th>  Log-Likelihood:    </th> <td> -345.27</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   696.5</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    87</td>      <th>  BIC:               </th> <td>   704.0</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
                           <td></td>                             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                                          <td>   95.2000</td> <td>    2.083</td> <td>   45.707</td> <td> 0.000</td> <td>   91.060</td> <td>   99.340</td>
</tr>
<tr>
  <th>C(kind, Treatment(reference="walking"))[T.rest]</th>    <td>   -4.3667</td> <td>    2.946</td> <td>   -1.482</td> <td> 0.142</td> <td>  -10.221</td> <td>    1.488</td>
</tr>
<tr>
  <th>C(kind, Treatment(reference="walking"))[T.running]</th> <td>   17.8667</td> <td>    2.946</td> <td>    6.066</td> <td> 0.000</td> <td>   12.012</td> <td>   23.721</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 9.099</td> <th>  Durbin-Watson:     </th> <td>   1.753</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.011</td> <th>  Jarque-Bera (JB):  </th> <td>   9.342</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.612</td> <th>  Prob(JB):          </th> <td> 0.00936</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.996</td> <th>  Cond. No.          </th> <td>    3.73</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>Notice now that the intercept the mean of walking, and to go to the ‘rest’ mean we need to subtract 4.3667 units. IJALM.</p>
</section>
<section id="factorial-anova-s-are-also-regressions">
<h2><span class="section-number">5.4. </span>Factorial ANOVA’s are also regressions<a class="headerlink" href="#factorial-anova-s-are-also-regressions" title="Permalink to this headline">#</a></h2>
<p>You guessed it - even more complex ANOVA designs can also be expressed as regressions, because the linear model approach underpins all of statistics. Interactions between one or more factors are also captured OLS.</p>
<p>We can use the <code class="docutils literal notranslate"><span class="pre">anova_lm</span></code> function from statsmodels to show this is the case. This takes a regression model and computes an ANOVA from it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Anova with Pingouin</span>
<span class="n">aov</span> <span class="o">=</span> <span class="n">pg</span><span class="o">.</span><span class="n">anova</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">exercise</span><span class="p">,</span> <span class="n">dv</span><span class="o">=</span><span class="s1">&#39;pulse&#39;</span><span class="p">,</span> <span class="n">between</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;kind&#39;</span><span class="p">,</span> <span class="s1">&#39;diet&#39;</span><span class="p">],</span> 
               <span class="n">ss_type</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">aov</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Source</th>
      <th>SS</th>
      <th>DF</th>
      <th>MS</th>
      <th>F</th>
      <th>p-unc</th>
      <th>np2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>kind</td>
      <td>8326.067</td>
      <td>2</td>
      <td>4163.033</td>
      <td>37.824</td>
      <td>0.000</td>
      <td>0.474</td>
    </tr>
    <tr>
      <th>1</th>
      <td>diet</td>
      <td>1261.878</td>
      <td>1</td>
      <td>1261.878</td>
      <td>11.465</td>
      <td>0.001</td>
      <td>0.120</td>
    </tr>
    <tr>
      <th>2</th>
      <td>kind * diet</td>
      <td>815.756</td>
      <td>2</td>
      <td>407.878</td>
      <td>3.706</td>
      <td>0.029</td>
      <td>0.081</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Residual</td>
      <td>9245.200</td>
      <td>84</td>
      <td>110.062</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the anova_lm function</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.anova</span> <span class="kn">import</span> <span class="n">anova_lm</span>

<span class="c1"># Fit a model as a linear regression that includes both kind, diet, and their interaction</span>
<span class="n">exercise_regression</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ kind + diet + kind:diet&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Conduct the anova</span>
<span class="n">reg_anova</span> <span class="o">=</span> <span class="n">anova_lm</span><span class="p">(</span><span class="n">exercise_regression</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">reg_anova</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kind</th>
      <td>2.0</td>
      <td>8326.067</td>
      <td>4163.033</td>
      <td>37.824</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>diet</th>
      <td>1.0</td>
      <td>1261.878</td>
      <td>1261.878</td>
      <td>11.465</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>kind:diet</th>
      <td>2.0</td>
      <td>815.756</td>
      <td>407.878</td>
      <td>3.706</td>
      <td>0.029</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>84.0</td>
      <td>9245.200</td>
      <td>110.062</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>What <code class="docutils literal notranslate"><span class="pre">anova_lm</span></code> does is described in more detail below, but hopefully this has convinced you of the fact that statistics IJALM. When you get to working with repeated measures ANOVA or beyond you can switch to hierarchical models to account for the similarity between data points, and the principle is the same. When to use a the linear model or ANOVA approach? Both are the same, but both have their advantages. If you <em>only</em> have categorical predictors, an ANOVA is typically more straightforward to use. But if you want to blend categorical and continuous predictors, you can only extend into the linear model approach which will never let you down, once the interpretation is mastered.</p>
</section>
<section id="a-deep-dive-into-statistics-factorial-anova-designs-as-linear-models">
<h2><span class="section-number">5.5. </span>A deep dive into statistics - factorial ANOVA designs as linear models<a class="headerlink" href="#a-deep-dive-into-statistics-factorial-anova-designs-as-linear-models" title="Permalink to this headline">#</a></h2>
<p>With a little (a lot) effort, we can understand the equivalence of things like <em>t</em>-test and ANOVA by delving into the foundations of classical statistics, which seeks to explain the <em>variability</em> in response variable using other variables.</p>
<p>What is variability anyway? Put simply, it is the amount a variable spreads out around its mean. For example, we can plot the <code class="docutils literal notranslate"><span class="pre">pulse</span></code> variable measured in the <code class="docutils literal notranslate"><span class="pre">exercise</span></code> dataset and examine its variability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show variability of pulse, black dot is the mean</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">stripplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">exercise</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;pulse&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">exercise</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;pulse&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">figure</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">figure</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ijalm_29_0.png" src="../_images/ijalm_29_0.png" />
</div>
</div>
<p>The variability is clear here. Lots of points are around the mean, with some further away. We can summarise this variability with a single number, which is <strong>vital</strong> in statistics - known as the <em>total sums of squares</em>. This number represents how variable a variable is! We compute the total sums of squares by:</p>
<ol class="simple">
<li><p>Compute the mean of a variable</p></li>
<li><p>Subtracting the mean from each observation in a variable</p></li>
<li><p>Squaring those values</p></li>
<li><p>Adding them all up</p></li>
</ol>
<p>As an aside, this sums of squares is the basis of the variance and standard deviation statistics. To get variance, divide the sums of squares by the number of datapoints, minus one. To get the standard deviation, take the square root of the variance.</p>
<p>Once we have this variability, we have another vital question - how can we <em>explain</em> this variability? Are there other variables that can account for this variability? As you have no doubt guessed, a linear model can do this. Lets see how. First we will compute the total sums of squares of the <code class="docutils literal notranslate"><span class="pre">pulse</span></code> variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute pulse sums of squares</span>
<span class="n">total_sums_squares</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">exercise</span><span class="p">[</span><span class="s1">&#39;pulse&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">exercise</span><span class="p">[</span><span class="s1">&#39;pulse&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">total_sums_squares</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>19648.9
</pre></div>
</div>
</div>
</div>
</section>
<section id="measuring-error-and-r-2">
<h2><span class="section-number">5.6. </span>Measuring error and <span class="math notranslate nohighlight">\(R^2\)</span><a class="headerlink" href="#measuring-error-and-r-2" title="Permalink to this headline">#</a></h2>
<p>The implicit way in which almost all statistical tests progress is via a <em>model comparison</em>. If we were given the <code class="docutils literal notranslate"><span class="pre">pulse</span></code> variable, and asked to make a guess about what each observation would be, we could use the mean of <code class="docutils literal notranslate"><span class="pre">pulse</span></code>. How would we measure our accuracy, or put another way, how well would we quantify our error using this method? The approach is to take the difference between the actual data and the prediction, known as the <strong>sums of squares residual</strong>, because the ‘residuals’ are what is ‘left over’ after our guesses. We take the differences, square them, and add them up.</p>
<p>In fact, these two sums of squares - the total and residual - are what we need to compute the <span class="math notranslate nohighlight">\(R^2\)</span>, using a simple formula - <span class="math notranslate nohighlight">\(1 - \frac{SSR}{SST}\)</span>. This tells us the percentage of variation explained in a literal sense.</p>
<p>We find an interesting equivalence here. If we use the mean of a variable as our best guess, then our sums of squares residual will be equal to the total sums of squares of a variable! We can fit a model using <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> and the <code class="docutils literal notranslate"><span class="pre">ols</span></code> class to demonstrate this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Remember that a variable ~ 1 is equivalent to using the mean to predict a variable</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># The model has a &#39;ssr&#39; attribute that holds our sums of squares residuals</span>
<span class="nb">print</span><span class="p">(</span><span class="n">base_model</span><span class="o">.</span><span class="n">ssr</span><span class="p">,</span> <span class="n">base_model</span><span class="o">.</span><span class="n">ssr</span> <span class="o">==</span> <span class="n">total_sums_squares</span><span class="p">)</span>

<span class="c1"># And also has a &#39;centered_tss&#39; attribute that stores its total sums of squares</span>
<span class="nb">print</span><span class="p">(</span><span class="n">base_model</span><span class="o">.</span><span class="n">centered_tss</span> <span class="o">==</span> <span class="n">total_sums_squares</span> <span class="ow">and</span> <span class="n">base_model</span><span class="o">.</span><span class="n">centered_tss</span> <span class="o">==</span> <span class="n">base_model</span><span class="o">.</span><span class="n">ssr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>19648.9 True
True
</pre></div>
</div>
</div>
</div>
<p>We can now compute directly the <span class="math notranslate nohighlight">\(R^2\)</span> of our model and compare it to the attribute stored by the model. In this case, the <span class="math notranslate nohighlight">\(R^2\)</span> is zero, as we have explained no variability by using the mean as a guess.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Manually compute</span>
<span class="n">rsquared</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">base_model</span><span class="o">.</span><span class="n">ssr</span> <span class="o">/</span> <span class="n">base_model</span><span class="o">.</span><span class="n">centered_tss</span><span class="p">)</span>

<span class="c1"># Check against the model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rsquared</span> <span class="o">==</span> <span class="n">base_model</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Now we know that the mean of a variable can be thought of as a ‘guess’ for the variability of a model, lets try and do better. Someone’s pulse is probably determined by the kind of activity they are doing. Luckily, we have this data, so lets add it as a predictor in a new model, and check the summary. This will tell us what the new <span class="math notranslate nohighlight">\(R^2\)</span> is.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add &#39;kind&#39; as a predictor</span>
<span class="n">with_kind</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1 + kind&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">with_kind</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>pulse</td>      <th>  R-squared:         </th> <td>   0.424</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.410</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.99</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 09 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>3.86e-11</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:56:24</td>     <th>  Log-Likelihood:    </th> <td> -345.27</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   696.5</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    87</td>      <th>  BIC:               </th> <td>   704.0</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>       <td>   90.8333</td> <td>    2.083</td> <td>   43.610</td> <td> 0.000</td> <td>   86.693</td> <td>   94.973</td>
</tr>
<tr>
  <th>kind[T.walking]</th> <td>    4.3667</td> <td>    2.946</td> <td>    1.482</td> <td> 0.142</td> <td>   -1.488</td> <td>   10.221</td>
</tr>
<tr>
  <th>kind[T.running]</th> <td>   22.2333</td> <td>    2.946</td> <td>    7.548</td> <td> 0.000</td> <td>   16.379</td> <td>   28.088</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 9.099</td> <th>  Durbin-Watson:     </th> <td>   1.753</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.011</td> <th>  Jarque-Bera (JB):  </th> <td>   9.342</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.612</td> <th>  Prob(JB):          </th> <td> 0.00936</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.996</td> <th>  Cond. No.          </th> <td>    3.73</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>We can assume from our large <span class="math notranslate nohighlight">\(R^2\)</span> that our sums of squared residuals are lower, which we can confirm and check the <span class="math notranslate nohighlight">\(R^2\)</span> manually. Our total sums of squares will be unchanged, as the <code class="docutils literal notranslate"><span class="pre">pulse</span></code> variable is the same.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show SSR and SST</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SSR = </span><span class="si">{</span><span class="n">with_kind</span><span class="o">.</span><span class="n">ssr</span><span class="si">}</span><span class="se">\n</span><span class="s1">SST = </span><span class="si">{</span><span class="n">with_kind</span><span class="o">.</span><span class="n">centered_tss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Directly</span>
<span class="n">rsquared</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">with_kind</span><span class="o">.</span><span class="n">ssr</span><span class="o">/</span><span class="n">with_kind</span><span class="o">.</span><span class="n">centered_tss</span><span class="p">)</span>

<span class="c1"># Compute Rsquare directly</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;R squared = </span><span class="si">{</span><span class="n">rsquared</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SSR = 11322.833333333332
SST = 19648.9
R squared = 0.42374212636161157
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="how-much-better-a-model-comparison-via-differences-in-error">
<h1><span class="section-number">6. </span>How much better? A model comparison via differences in error<a class="headerlink" href="#how-much-better-a-model-comparison-via-differences-in-error" title="Permalink to this headline">#</a></h1>
<p>Our sums of squares residual has gone down - we have less error if we use exercise kind as a predictor. Great! But, how much should we care about this? Is this a meaningful change or not? How can we evaluate the usefulness of our predictors? The way to do this is by using a comparison of linear models, which gives us an <span class="math notranslate nohighlight">\(F\)</span>-ratio - you will have spotted these in the summary, but we can get this ourselves, by getting some key numbers from our model.</p>
<p>What we do is take the error from our current model, and see how different it is from the previous model. We normalise that difference in error by the difference in the number of predictors between models. For example, if model A has a high error with three predictors, but model B has a very low error but with an additional 25 predictors, we may not be so impressed compared to the same lower error with a model with a single additional predictor.</p>
<p>So how do we compare the usefulness of our predictors? We compare the sums of squares residuals of our mean only and sums of squares residuals of our current model, with <code class="docutils literal notranslate"><span class="pre">kind</span></code> as a predictor, to the mean-only model.</p>
<p>There are several steps involved:</p>
<ol class="simple">
<li><p>Work out the difference between the residual sums of squares in the mean only model, and the current model. We can call this the ss-diff.</p></li>
<li><p>Get the SSR of the current model - this is the error we will compare against.</p></li>
<li><p>Get the residual degrees of freedom in the mean only model, and the current model. The residual degrees of freedom, though fancy-sounding, are represented by the number of observations, minus one, minus the number of predictors in a model. Work out the difference between these two values.</p></li>
<li><p>Normalise the SSR of the current model by the residual degrees of freedom, by division.</p></li>
<li><p>Then divide the ss-diff by the differences in the residual degrees of freedom between the models. These can be thought of as the mean squares difference in error by the mean squares error in the current model.</p></li>
<li><p>Dividing the resulting values gives your <span class="math notranslate nohighlight">\(F\)</span> value which can be tested for significance.</p></li>
</ol>
<p>That seems like a lot of work. Thankfully, the <code class="docutils literal notranslate"><span class="pre">anova_lm</span></code> function, when called with two arguments, will do all of this for us! Let’s see how it performs with the <code class="docutils literal notranslate"><span class="pre">base_model</span></code> and the <code class="docutils literal notranslate"><span class="pre">with_kind</span></code> models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anova_lm</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">with_kind</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df_resid</th>
      <th>ssr</th>
      <th>df_diff</th>
      <th>ss_diff</th>
      <th>F</th>
      <th>Pr(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>89.0</td>
      <td>19648.900000</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>87.0</td>
      <td>11322.833333</td>
      <td>2.0</td>
      <td>8326.066667</td>
      <td>31.987038</td>
      <td>3.862193e-11</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This means the difference in <span class="math notranslate nohighlight">\(R^2\)</span> - from zero to .42 when including <code class="docutils literal notranslate"><span class="pre">kind</span></code> is a significant result. We can also check this calculation manually:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># What is the difference in residual sums of squares in the models - how big is the difference in error?</span>
<span class="n">ss_diff</span> <span class="o">=</span> <span class="n">with_kind</span><span class="o">.</span><span class="n">ssr</span> <span class="o">-</span> <span class="n">base_model</span><span class="o">.</span><span class="n">ssr</span>

<span class="c1"># What is the residual SS of the new model?</span>
<span class="n">current_ssr</span> <span class="o">=</span> <span class="n">with_kind</span><span class="o">.</span><span class="n">ssr</span>

<span class="c1"># What is the difference in the residual degrees of freedom between models?</span>
<span class="c1"># ie - how many datapoints are &#39;left&#39; over in both?</span>
<span class="n">model_df_diff</span> <span class="o">=</span> <span class="n">with_kind</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">-</span> <span class="n">base_model</span><span class="o">.</span><span class="n">df_resid</span>

<span class="c1"># What is the residual degrees of freedom in our new model?</span>
<span class="c1"># nobs - number of observations - its also in .df_resid!</span>
<span class="n">resid_df</span> <span class="o">=</span> <span class="n">with_kind</span><span class="o">.</span><span class="n">nobs</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">with_kind</span><span class="o">.</span><span class="n">df_model</span>

<span class="c1"># Normalise our errors</span>
<span class="n">mean_squares_error_difference</span> <span class="o">=</span> <span class="n">ss_diff</span><span class="o">/</span><span class="n">model_df_diff</span>
<span class="n">mean_squares_error</span> <span class="o">=</span> <span class="n">current_ssr</span><span class="o">/</span><span class="n">resid_df</span>

<span class="c1"># Get F</span>
<span class="n">F</span> <span class="o">=</span> <span class="n">mean_squares_error_difference</span><span class="o">/</span><span class="n">mean_squares_error</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/alexjones/opt/anaconda3/envs/py10/lib/python3.10/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.1, the latest is 0.5.2.
Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.
  return warn(
</pre></div>
</div>
</div>
</div>
<p>Now, we can check the F value matches the F value computed by our <code class="docutils literal notranslate"><span class="pre">with_kind</span></code> model, as this is what the model was doing to begin with to check the model fit!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">F</span> <span class="o">==</span> <span class="n">with_kind</span><span class="o">.</span><span class="n">fvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<section id="what-anova-does">
<h2><span class="section-number">6.1. </span>What ANOVA does<a class="headerlink" href="#what-anova-does" title="Permalink to this headline">#</a></h2>
<p>When computing a factorial ANOVA, the analysis proceeds by building a stepwise model, examining the change in the amount of variance explained in each step, and computing the significance of it, moving from a model with no predictors to those with more.</p>
<p>Let us fit our full model on the <code class="docutils literal notranslate"><span class="pre">exercise</span></code> data, with two predictors <code class="docutils literal notranslate"><span class="pre">kind</span></code> and <code class="docutils literal notranslate"><span class="pre">diet</span></code>, and their interaction, using a linear model, and the compute the ANOVA using <code class="docutils literal notranslate"><span class="pre">anova_lm</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit model</span>
<span class="n">full_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1 + kind + diet + kind:diet&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Get ANOVA</span>
<span class="n">anova</span> <span class="o">=</span> <span class="n">anova_lm</span><span class="p">(</span><span class="n">full_model</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">anova</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kind</th>
      <td>2.0</td>
      <td>8326.067</td>
      <td>4163.033</td>
      <td>37.824</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>diet</th>
      <td>1.0</td>
      <td>1261.878</td>
      <td>1261.878</td>
      <td>11.465</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>kind:diet</th>
      <td>2.0</td>
      <td>815.756</td>
      <td>407.878</td>
      <td>3.706</td>
      <td>0.029</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>84.0</td>
      <td>9245.200</td>
      <td>110.062</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here, the question is whether the ‘full’ model - the one containing both the predictors and their interaction - is a better fit to the data than the models that precede it. The key thing to rememeber is that the model with the interaction has all the predictors in it, while the ‘diet’ model has kind and diet, with no interaction, and the ‘kind’ model only has that predictor, and nothing else.</p>
<p>First, build all the component models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the separate step models</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">kind</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1 + kind&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">kind_diet</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1 + kind + diet&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">full</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;pulse ~ 1 + kind + diet + kind:diet&#39;</span><span class="p">,</span> <span class="n">exercise</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can now recreate the analysis of the ANOVA table by comparing models, using the error from the full model (the one with all the predictors and interaction in), and looking at the differences in sums of squares residual between the models, divided by their respective degrees of freedom.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, get the mean-squared-error from the full model</span>
<span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">full</span><span class="o">.</span><span class="n">mse_resid</span>

<span class="c1"># What is the effect of adding diet to the model, over and above kind?</span>
<span class="n">diet_F</span> <span class="o">=</span> <span class="p">((</span><span class="n">kind_diet</span><span class="o">.</span><span class="n">ssr</span> <span class="o">-</span> <span class="n">kind</span><span class="o">.</span><span class="n">ssr</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">kind_diet</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">-</span> <span class="n">kind</span><span class="o">.</span><span class="n">df_resid</span><span class="p">))</span> <span class="o">/</span> <span class="n">mean_squared_error</span>

<span class="c1"># Or, what about just kind on its own?</span>
<span class="n">kind_F</span> <span class="o">=</span> <span class="p">((</span><span class="n">kind</span><span class="o">.</span><span class="n">ssr</span> <span class="o">-</span> <span class="n">base_model</span><span class="o">.</span><span class="n">ssr</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">kind</span><span class="o">.</span><span class="n">df_resid</span> <span class="o">-</span> <span class="n">base_model</span><span class="o">.</span><span class="n">df_resid</span><span class="p">))</span> <span class="o">/</span> <span class="n">mean_squared_error</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show</span>
<span class="n">display</span><span class="p">(</span><span class="n">anova</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">diet_F</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">kind_F</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kind</th>
      <td>2.0</td>
      <td>8326.07</td>
      <td>4163.03</td>
      <td>37.82</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>diet</th>
      <td>1.0</td>
      <td>1261.88</td>
      <td>1261.88</td>
      <td>11.47</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>kind:diet</th>
      <td>2.0</td>
      <td>815.76</td>
      <td>407.88</td>
      <td>3.71</td>
      <td>0.03</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>84.0</td>
      <td>9245.20</td>
      <td>110.06</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>11.47 37.82
</pre></div>
</div>
</div>
</div>
<p>Of course, the <code class="docutils literal notranslate"><span class="pre">anova_lm</span></code> function does this is all for you. If you wanted to see the differences in <span class="math notranslate nohighlight">\(R^2\)</span> associated with these F tests - the actual effect of interest - we can compute them through simple subtraction of the model R square properties.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get R squared </span>
<span class="n">r_squared</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kind&#39;</span><span class="p">:</span> <span class="n">kind</span><span class="o">.</span><span class="n">rsquared</span> <span class="o">-</span> <span class="n">base_model</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span>
            <span class="s1">&#39;diet&#39;</span><span class="p">:</span> <span class="n">kind_diet</span><span class="o">.</span><span class="n">rsquared</span> <span class="o">-</span> <span class="n">kind</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span>
            <span class="s1">&#39;kind:diet&#39;</span><span class="p">:</span> <span class="n">full</span><span class="o">.</span><span class="n">rsquared</span> <span class="o">-</span> <span class="n">kind_diet</span><span class="o">.</span><span class="n">rsquared</span>
            <span class="p">}</span>
<span class="c1"># Turn this to a series</span>
<span class="n">r_sq</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">r_squared</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">anova</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;R2_change&#39;</span><span class="p">)</span>

<span class="c1"># Add to our anova table</span>
<span class="n">full_anova</span> <span class="o">=</span> <span class="n">anova</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">r_sq</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">full_anova</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
      <th>R2_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kind</th>
      <td>2.0</td>
      <td>8326.067</td>
      <td>4163.033</td>
      <td>37.824</td>
      <td>0.000</td>
      <td>0.424</td>
    </tr>
    <tr>
      <th>diet</th>
      <td>1.0</td>
      <td>1261.878</td>
      <td>1261.878</td>
      <td>11.465</td>
      <td>0.001</td>
      <td>0.064</td>
    </tr>
    <tr>
      <th>kind:diet</th>
      <td>2.0</td>
      <td>815.756</td>
      <td>407.878</td>
      <td>3.706</td>
      <td>0.029</td>
      <td>0.042</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>84.0</td>
      <td>9245.200</td>
      <td>110.062</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And if we compute the total <span class="math notranslate nohighlight">\(R^2\)</span> from this table, it will be equal to the <span class="math notranslate nohighlight">\(R^2\)</span> of the full regression model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r2_sum</span> <span class="o">=</span> <span class="n">full_anova</span><span class="p">[</span><span class="s1">&#39;R2_change&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r2_sum</span> <span class="o">==</span> <span class="n">full</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Once you have arranged your data into a format that can be easily analysed, then computing a general range of statistical inferences is made easy by the range of packages in Python. The ability to use a single language to complete all analysis steps is a huge plus. The world of statistical inference is enormous and Python is extremely well supported for these kinds of analyses - explore online and the chances are there is a package out there to suit your needs!</p>
<p>Good luck in your data adventures with Python!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapter6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="lmm.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4. </span>Hierarchical or mixed models</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Alex Jones, Ph.D<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>